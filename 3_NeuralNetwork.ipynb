{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ThreadTheRipper\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                  text  \\\n0    The accelerator programs have sub-portfolios o...   \n1    Also by means of BNDES Finem, we offer credit ...   \n2    Climate change Climate change exposes UPM to v...   \n3    Several tools and methodologies aimed at asses...   \n4    We worked with the UK government to accelerate...   \n..                                                 ...   \n395  At the beginning of 2019, VINCI Airports signe...   \n396  We have also signed up to the Partnership for ...   \n397  Suzano also is involved and spearheads externa...   \n398  Risks to the Group’s reputation Risks include ...   \n399  UBS is also involved in other activities to re...   \n\n                                                tokens  \n0    [the, accelerator, programs, have, of, focused...  \n1    [also, by, means, of, bndes, finem, we, offer,...  \n2    [climate, change, climate, change, exposes, up...  \n3    [several, tools, and, methodologies, aimed, at...  \n4    [we, worked, with, the, uk, government, to, ac...  \n..                                                 ...  \n395  [at, the, beginning, of, 2019, vinci, airports...  \n396  [we, have, also, signed, up, to, the, partners...  \n397  [suzano, also, is, involved, and, spearheads, ...  \n398  [risks, to, the, group, s, reputation, risks, ...  \n399  [ubs, is, also, involved, in, other, activitie...  \n\n[400 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The accelerator programs have sub-portfolios o...</td>\n      <td>[the, accelerator, programs, have, of, focused...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Also by means of BNDES Finem, we offer credit ...</td>\n      <td>[also, by, means, of, bndes, finem, we, offer,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Climate change Climate change exposes UPM to v...</td>\n      <td>[climate, change, climate, change, exposes, up...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Several tools and methodologies aimed at asses...</td>\n      <td>[several, tools, and, methodologies, aimed, at...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We worked with the UK government to accelerate...</td>\n      <td>[we, worked, with, the, uk, government, to, ac...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>At the beginning of 2019, VINCI Airports signe...</td>\n      <td>[at, the, beginning, of, 2019, vinci, airports...</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>We have also signed up to the Partnership for ...</td>\n      <td>[we, have, also, signed, up, to, the, partners...</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>Suzano also is involved and spearheads externa...</td>\n      <td>[suzano, also, is, involved, and, spearheads, ...</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>Risks to the Group’s reputation Risks include ...</td>\n      <td>[risks, to, the, group, s, reputation, risks, ...</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>UBS is also involved in other activities to re...</td>\n      <td>[ubs, is, also, involved, in, other, activitie...</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "nltk.download('punkt')\n",
    "\n",
    "path = str(Path.cwd()) + '\\project_training.json'\n",
    "# print(path)\n",
    "# Read the JSON file\n",
    "with open(path, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Load the JSON data into a dataframe\n",
    "df_train = pd.read_json(data)\n",
    "\n",
    "# Create a dataframes for the text and the climate label\n",
    "df_text = pd.DataFrame(df_train, columns=['text'])\n",
    "df_climate = pd.DataFrame(df_train, columns=['climate'])\n",
    "# Keep rows where df_climate is 'yes'\n",
    "df_filtered = df_train.loc[df_climate['climate'] == 'yes']\n",
    "\n",
    "# Split the filtered dataframe into separate dataframes\n",
    "df_text_climate_yes = pd.DataFrame(df_filtered, columns=['text'])\n",
    "df_sentiment = pd.DataFrame(df_filtered, columns=['sentiment'])\n",
    "df_commitment = pd.DataFrame(df_filtered, columns=['commitment'])\n",
    "df_specificity = pd.DataFrame(df_filtered, columns=['specificity'])\n",
    "# turn all labels into numerical labels\n",
    "\n",
    "df_climate = df_climate.replace({'yes': 1, 'no': 0})\n",
    "# opportunity/neutral/risk\n",
    "df_sentiment = df_sentiment.replace({'opportunity': 0, 'neutral': 1, 'risk': 2})\n",
    "# yes/no\n",
    "df_commitment = df_commitment.replace({'yes': 1, 'no': 0})\n",
    "# specific language/non-specific language\n",
    "df_specificity = df_specificity.replace({'spec': 1, 'non': 0})\n",
    "\n",
    "path = str(Path.cwd()) + '\\project_validation.json'\n",
    "with open(path, 'r') as f_test:\n",
    "    data_test = f_test.read()\n",
    "\n",
    "# Load the JSON data into a dataframe\n",
    "df_test = pd.read_json(data_test)\n",
    "df_text_test = pd.DataFrame(df_test, columns=['text'])\n",
    "df_climate_test = pd.DataFrame(df_test, columns=['climate'])\n",
    "# Keep rows where df_climate is 'yes'\n",
    "df_filtered_test = df_test.loc[df_climate_test['climate'] == 'yes']\n",
    "df_text_test_climate_yes = pd.DataFrame(df_filtered_test, columns=['text'])\n",
    "df_sentiment_test = pd.DataFrame(df_filtered_test, columns=['sentiment'])\n",
    "df_commitment_test = pd.DataFrame(df_filtered_test, columns=['commitment'])\n",
    "df_specificity_test = pd.DataFrame(df_filtered_test, columns=['specificity'])\n",
    "# same for climate classification text data\n",
    "df_climate_test = df_climate_test.replace({'yes': 1, 'no': 0})\n",
    "# opportunity/neutral/risk\n",
    "df_sentiment_test = df_sentiment_test.replace({'opportunity': 0, 'neutral': 1, 'risk': 2})\n",
    "# yes/no\n",
    "df_commitment_test = df_commitment_test.replace({'yes': 1, 'no': 0})\n",
    "# specific language/non-specific language\n",
    "df_specificity_test = df_specificity_test.replace({'spec': 1, 'non': 0})\n",
    "\n",
    "def lowercase_delete_special_characters(tokens):\n",
    "    modified_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isalpha():\n",
    "            modified_tokens.append(token.lower())\n",
    "        elif token.isnumeric():\n",
    "            modified_tokens.append(token)\n",
    "    return modified_tokens\n",
    "\n",
    "\n",
    "df_text['tokens'] = df_text['text'].apply(nltk.word_tokenize)\n",
    "df_text['tokens'] = df_text['tokens'].apply(lowercase_delete_special_characters)\n",
    "\n",
    "df_text_climate_yes['tokens'] = df_text_climate_yes['text'].apply(nltk.word_tokenize)\n",
    "df_text_climate_yes['tokens'] = df_text_climate_yes['tokens'].apply(lowercase_delete_special_characters)\n",
    "\n",
    "df_text_test['tokens'] = df_text_test['text'].apply(nltk.word_tokenize)\n",
    "df_text_test['tokens'] = df_text_test['tokens'].apply(lowercase_delete_special_characters)\n",
    "\n",
    "df_text_test_climate_yes['tokens'] = df_text_test_climate_yes['text'].apply(nltk.word_tokenize)\n",
    "df_text_test_climate_yes['tokens'] = df_text_test_climate_yes['tokens'].apply(lowercase_delete_special_characters)\n",
    "\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_word2vec = KeyedVectors.load_word2vec_format('glove.6B.300d.txt', binary=False, no_header=True)\n",
    "# print(model.most_similar(positive=['sustainability']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n",
      "269\n",
      "418\n",
      "269\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                  text  \\\n0    The accelerator programs have sub-portfolios o...   \n1    Also by means of BNDES Finem, we offer credit ...   \n2    Climate change Climate change exposes UPM to v...   \n3    Several tools and methodologies aimed at asses...   \n4    We worked with the UK government to accelerate...   \n..                                                 ...   \n395  At the beginning of 2019, VINCI Airports signe...   \n396  We have also signed up to the Partnership for ...   \n397  Suzano also is involved and spearheads externa...   \n398  Risks to the Group’s reputation Risks include ...   \n399  UBS is also involved in other activities to re...   \n\n                                                tokens  \\\n0    [the, accelerator, programs, have, of, focused...   \n1    [also, by, means, of, bndes, finem, we, offer,...   \n2    [climate, change, climate, change, exposes, up...   \n3    [several, tools, and, methodologies, aimed, at...   \n4    [we, worked, with, the, uk, government, to, ac...   \n..                                                 ...   \n395  [at, the, beginning, of, 2019, vinci, airports...   \n396  [we, have, also, signed, up, to, the, partners...   \n397  [suzano, also, is, involved, and, spearheads, ...   \n398  [risks, to, the, group, s, reputation, risks, ...   \n399  [ubs, is, also, involved, in, other, activitie...   \n\n                                            tokens_num  num_of_tokens  \n0    [1, 21736, 1010, 34, 4, 2336, 9161, 1808, 22, ...             28  \n1    [53, 22, 890, 4, 107047, 54, 902, 1165, 26, 1,...             31  \n2    [1949, 512, 1949, 512, 24518, 49056, 5, 2166, ...            129  \n3    [202, 4316, 6, 40100, 1637, 23, 13228, 1, 4764...            289  \n4    [54, 763, 18, 1, 2047, 79, 5, 8710, 1, 3670, 5...             61  \n..                                                 ...            ...  \n395  [23, 1, 1085, 4, 40469, 17581, 4949, 759, 8, 9...             66  \n396  [54, 34, 53, 759, 61, 5, 1, 2884, 11, 4137, 35...             60  \n397  [219104, 53, 15, 792, 6, 59691, 3752, 1219, 12...             28  \n398  [3344, 5, 1, 130, 1535, 3148, 3344, 489, 2538,...             56  \n399  [9466, 15, 53, 792, 7, 69, 1219, 5, 1681, 1055...             59  \n\n[400 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tokens</th>\n      <th>tokens_num</th>\n      <th>num_of_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The accelerator programs have sub-portfolios o...</td>\n      <td>[the, accelerator, programs, have, of, focused...</td>\n      <td>[1, 21736, 1010, 34, 4, 2336, 9161, 1808, 22, ...</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Also by means of BNDES Finem, we offer credit ...</td>\n      <td>[also, by, means, of, bndes, finem, we, offer,...</td>\n      <td>[53, 22, 890, 4, 107047, 54, 902, 1165, 26, 1,...</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Climate change Climate change exposes UPM to v...</td>\n      <td>[climate, change, climate, change, exposes, up...</td>\n      <td>[1949, 512, 1949, 512, 24518, 49056, 5, 2166, ...</td>\n      <td>129</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Several tools and methodologies aimed at asses...</td>\n      <td>[several, tools, and, methodologies, aimed, at...</td>\n      <td>[202, 4316, 6, 40100, 1637, 23, 13228, 1, 4764...</td>\n      <td>289</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>We worked with the UK government to accelerate...</td>\n      <td>[we, worked, with, the, uk, government, to, ac...</td>\n      <td>[54, 763, 18, 1, 2047, 79, 5, 8710, 1, 3670, 5...</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>At the beginning of 2019, VINCI Airports signe...</td>\n      <td>[at, the, beginning, of, 2019, vinci, airports...</td>\n      <td>[23, 1, 1085, 4, 40469, 17581, 4949, 759, 8, 9...</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>We have also signed up to the Partnership for ...</td>\n      <td>[we, have, also, signed, up, to, the, partners...</td>\n      <td>[54, 34, 53, 759, 61, 5, 1, 2884, 11, 4137, 35...</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>Suzano also is involved and spearheads externa...</td>\n      <td>[suzano, also, is, involved, and, spearheads, ...</td>\n      <td>[219104, 53, 15, 792, 6, 59691, 3752, 1219, 12...</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>Risks to the Group’s reputation Risks include ...</td>\n      <td>[risks, to, the, group, s, reputation, risks, ...</td>\n      <td>[3344, 5, 1, 130, 1535, 3148, 3344, 489, 2538,...</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>UBS is also involved in other activities to re...</td>\n      <td>[ubs, is, also, involved, in, other, activitie...</td>\n      <td>[9466, 15, 53, 792, 7, 69, 1219, 5, 1681, 1055...</td>\n      <td>59</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of dimensions in the Word2Vec model\n",
    "num_dimensions = model_word2vec.vector_size\n",
    "\n",
    "# replace the tokens with their numerical representations (word_embedding index +1 to account for OOV words in embedding matrix later)\n",
    "df_text['tokens_num'] = df_text['tokens'].apply(lambda x: [model_word2vec.get_index(j)+1 for j in x if j in model_word2vec.index_to_key])\n",
    "# calculate number of tokens per paragraph\n",
    "df_text['num_of_tokens'] = df_text['tokens_num'].apply(len)\n",
    "# print the highest number of tokens for a paragraph (needed for padding to make paragraphs the same length)\n",
    "print(df_text['num_of_tokens'].max())\n",
    "\n",
    "df_text_test['tokens_num'] = df_text_test['tokens'].apply(lambda x: [model_word2vec.get_index(j)+1 for j in x if j in model_word2vec.index_to_key])\n",
    "df_text_test['num_of_tokens'] = df_text_test['tokens_num'].apply(len)\n",
    "print(df_text_test['num_of_tokens'].max())\n",
    "\n",
    "df_text_climate_yes['tokens_num'] = df_text_climate_yes['tokens'].apply(lambda x: [model_word2vec.get_index(j)+1 for j in x if j in model_word2vec.index_to_key])\n",
    "df_text_climate_yes['num_of_tokens'] = df_text_climate_yes['tokens_num'].apply(len)\n",
    "print(df_text_climate_yes['num_of_tokens'].max())\n",
    "\n",
    "df_text_test_climate_yes['tokens_num'] = df_text_test_climate_yes['tokens'].apply(lambda x: [model_word2vec.get_index(j)+1 for j in x if j in model_word2vec.index_to_key])\n",
    "df_text_test_climate_yes['num_of_tokens'] = df_text_test_climate_yes['tokens_num'].apply(len)\n",
    "print(df_text_test_climate_yes['num_of_tokens'].max())\n",
    "\n",
    "# define maximum number of tokens for each paragraph, number is based on preprocessing and can change if preprocessing is modified\n",
    "max_len_for_padding = 420\n",
    "# pad lists of tokens at the end to make them uniform in length\n",
    "padding_type = 'post'\n",
    "\n",
    "# padding of token lists\n",
    "df_text['tokens_num'] = df_text['tokens_num'].apply(lambda x: pad_sequences([x], maxlen=max_len_for_padding, padding=padding_type)[0])\n",
    "\n",
    "df_text_test['tokens_num'] = df_text_test['tokens_num'].apply(lambda x: pad_sequences([x], maxlen=max_len_for_padding, padding=padding_type)[0])\n",
    "\n",
    "df_text_climate_yes['tokens_num'] = df_text_climate_yes['tokens_num'].apply(lambda x: pad_sequences([x], maxlen=max_len_for_padding, padding=padding_type)[0])\n",
    "\n",
    "df_text_test_climate_yes['tokens_num'] = df_text_test_climate_yes['tokens_num'].apply(lambda x: pad_sequences([x], maxlen=max_len_for_padding, padding=padding_type)[0])\n",
    "\n",
    "df_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                       document_vector  climate\n0    [1, 21736, 1010, 34, 4, 2336, 9161, 1808, 22, ...        1\n1    [53, 22, 890, 4, 107047, 54, 902, 1165, 26, 1,...        0\n2    [1949, 512, 1949, 512, 24518, 49056, 5, 2166, ...        1\n3    [202, 4316, 6, 40100, 1637, 23, 13228, 1, 4764...        1\n4    [54, 763, 18, 1, 2047, 79, 5, 8710, 1, 3670, 5...        1\n..                                                 ...      ...\n395  [28155, 5920, 1089, 845, 7, 110, 1421, 145, 62...        0\n396  [207, 2044, 5679, 20740, 94834, 13160, 33, 565...        1\n397  [448, 14, 163, 300, 4, 635, 5325, 5473, 54, 75...        1\n398  [7, 40469, 203475, 15800, 1, 43010, 1765, 3360...        1\n399  [2502, 5, 3934, 4251, 26, 4561, 1180, 16685, 1...        1\n\n[800 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document_vector</th>\n      <th>climate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[1, 21736, 1010, 34, 4, 2336, 9161, 1808, 22, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[53, 22, 890, 4, 107047, 54, 902, 1165, 26, 1,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[1949, 512, 1949, 512, 24518, 49056, 5, 2166, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[202, 4316, 6, 40100, 1637, 23, 13228, 1, 4764...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[54, 763, 18, 1, 2047, 79, 5, 8710, 1, 3670, 5...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>[28155, 5920, 1089, 845, 7, 110, 1421, 145, 62...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>[207, 2044, 5679, 20740, 94834, 13160, 33, 565...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>[448, 14, 163, 300, 4, 635, 5325, 5473, 54, 75...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>[7, 40469, 203475, 15800, 1, 43010, 1765, 3360...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>[2502, 5, 3934, 4251, 26, 4561, 1180, 16685, 1...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>800 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge all document representations as numbers for each classification task including their label\n",
    "\n",
    "df_text_all = pd.concat([df_text['tokens_num'], df_text_test['tokens_num']])\n",
    "df_text_climate_yes_all = pd.concat([df_text_climate_yes['tokens_num'], df_text_test_climate_yes['tokens_num']])\n",
    "\n",
    "df_climate_all = pd.concat([df_climate, df_climate_test])\n",
    "df_sentiment_all = pd.concat([df_sentiment, df_sentiment_test])\n",
    "df_commitment_all = pd.concat([df_commitment, df_commitment_test])\n",
    "df_specificity_all = pd.concat([df_specificity, df_specificity_test])\n",
    "\n",
    "df_climate_all['document_vector'] = df_text_all\n",
    "df_climate_all = df_climate_all.iloc[:,[1,0]]\n",
    "\n",
    "df_sentiment_all['document_vector'] = df_text_climate_yes_all\n",
    "df_sentiment_all = df_sentiment_all.iloc[:,[1,0]]\n",
    "\n",
    "df_commitment_all['document_vector'] = df_text_climate_yes_all\n",
    "df_commitment_all = df_commitment_all.iloc[:,[1,0]]\n",
    "\n",
    "df_specificity_all['document_vector'] = df_text_climate_yes_all\n",
    "df_specificity_all = df_specificity_all.iloc[:,[1,0]]\n",
    "\n",
    "df_climate_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5527922439205444394\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6277824512\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9287549024288082359\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:42:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# necessary to check whether GPU was detected\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_50 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_200 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_201 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_50 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_202 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_203 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_50  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "11/11 [==============================] - 2s 100ms/step - loss: 0.5129 - acc: 0.7695 - val_loss: 0.4389 - val_acc: 0.8516\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4658 - acc: 0.8242 - val_loss: 0.4284 - val_acc: 0.8516\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4304 - acc: 0.8242 - val_loss: 0.3071 - val_acc: 0.8516\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3146 - acc: 0.8242 - val_loss: 0.2595 - val_acc: 0.8516\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.2115 - acc: 0.8516 - val_loss: 0.2021 - val_acc: 0.8594\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.1375 - acc: 0.9355 - val_loss: 0.2763 - val_acc: 0.8828\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.1192 - acc: 0.9453 - val_loss: 0.2745 - val_acc: 0.8672\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0947 - acc: 0.9609 - val_loss: 0.2616 - val_acc: 0.8828\n",
      "Validation accuracy: 0.8828125, loss: 0.2616167664527893\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82        30\n",
      "           1       0.98      0.92      0.95       130\n",
      "\n",
      "    accuracy                           0.93       160\n",
      "   macro avg       0.86      0.93      0.89       160\n",
      "weighted avg       0.94      0.93      0.93       160\n",
      "\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_51 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_204 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_205 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_51 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_206 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_207 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_51  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "11/11 [==============================] - 2s 102ms/step - loss: 0.5010 - acc: 0.7969 - val_loss: 0.4769 - val_acc: 0.8125\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4514 - acc: 0.8281 - val_loss: 0.4242 - val_acc: 0.8125\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3767 - acc: 0.8281 - val_loss: 0.2986 - val_acc: 0.8125\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.2560 - acc: 0.8281 - val_loss: 0.1989 - val_acc: 0.9297\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.1588 - acc: 0.9336 - val_loss: 0.1484 - val_acc: 0.9297\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.1502 - acc: 0.9336 - val_loss: 0.1807 - val_acc: 0.9297\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.1123 - acc: 0.9551 - val_loss: 0.2035 - val_acc: 0.9141\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.0753 - acc: 0.9785 - val_loss: 0.1614 - val_acc: 0.9375\n",
      "Validation accuracy: 0.9375, loss: 0.16140727698802948\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86        27\n",
      "           1       0.98      0.96      0.97       133\n",
      "\n",
      "    accuracy                           0.95       160\n",
      "   macro avg       0.90      0.93      0.91       160\n",
      "weighted avg       0.95      0.95      0.95       160\n",
      "\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_52 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_208 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_209 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_52 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_210 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_211 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_52  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "11/11 [==============================] - 2s 101ms/step - loss: 0.5313 - acc: 0.7637 - val_loss: 0.4162 - val_acc: 0.8516\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.4570 - acc: 0.8164 - val_loss: 0.4003 - val_acc: 0.8516\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.3980 - acc: 0.8164 - val_loss: 0.2724 - val_acc: 0.8516\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.2878 - acc: 0.8164 - val_loss: 0.2016 - val_acc: 0.8516\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.2023 - acc: 0.8711 - val_loss: 0.1654 - val_acc: 0.9062\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.1305 - acc: 0.9473 - val_loss: 0.2636 - val_acc: 0.9062\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.1418 - acc: 0.9414 - val_loss: 0.1824 - val_acc: 0.9141\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.0957 - acc: 0.9688 - val_loss: 0.1642 - val_acc: 0.9297\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.0694 - acc: 0.9707 - val_loss: 0.1622 - val_acc: 0.9141\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0715 - acc: 0.9629 - val_loss: 0.1998 - val_acc: 0.9219\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0560 - acc: 0.9746 - val_loss: 0.2420 - val_acc: 0.9141\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0371 - acc: 0.9805 - val_loss: 0.1905 - val_acc: 0.9453\n",
      "Validation accuracy: 0.9453125, loss: 0.19046548008918762\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.75        26\n",
      "           1       0.95      0.96      0.95       134\n",
      "\n",
      "    accuracy                           0.92       160\n",
      "   macro avg       0.85      0.84      0.85       160\n",
      "weighted avg       0.92      0.92      0.92       160\n",
      "\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_53 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_212 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_213 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_53 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_214 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_215 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_53  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "11/11 [==============================] - 2s 94ms/step - loss: 0.4743 - acc: 0.7891 - val_loss: 0.4896 - val_acc: 0.7969\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.4142 - acc: 0.8359 - val_loss: 0.4120 - val_acc: 0.7969\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3218 - acc: 0.8359 - val_loss: 0.3070 - val_acc: 0.7969\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.2413 - acc: 0.8359 - val_loss: 0.2146 - val_acc: 0.8516\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.1622 - acc: 0.9277 - val_loss: 0.1540 - val_acc: 0.9219\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.1260 - acc: 0.9434 - val_loss: 0.1323 - val_acc: 0.9297\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.1014 - acc: 0.9512 - val_loss: 0.1307 - val_acc: 0.9219\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0730 - acc: 0.9648 - val_loss: 0.1168 - val_acc: 0.9375\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0578 - acc: 0.9785 - val_loss: 0.2829 - val_acc: 0.9375\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0987 - acc: 0.9668 - val_loss: 0.1436 - val_acc: 0.9531\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0586 - acc: 0.9805 - val_loss: 0.1323 - val_acc: 0.9297\n",
      "Validation accuracy: 0.9296875, loss: 0.13231588900089264\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79        29\n",
      "           1       0.96      0.94      0.95       131\n",
      "\n",
      "    accuracy                           0.92       160\n",
      "   macro avg       0.86      0.88      0.87       160\n",
      "weighted avg       0.92      0.92      0.92       160\n",
      "\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_54 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_216 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_217 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_54 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_218 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_219 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_54  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "11/11 [==============================] - 2s 104ms/step - loss: 0.4896 - acc: 0.8105 - val_loss: 0.4153 - val_acc: 0.8438\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.4359 - acc: 0.8203 - val_loss: 0.3583 - val_acc: 0.8438\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3185 - acc: 0.8203 - val_loss: 0.2404 - val_acc: 0.8438\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.2014 - acc: 0.8711 - val_loss: 0.1984 - val_acc: 0.8828\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.1497 - acc: 0.9375 - val_loss: 0.2130 - val_acc: 0.8906\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.1439 - acc: 0.9375 - val_loss: 0.2074 - val_acc: 0.8828\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0861 - acc: 0.9707 - val_loss: 0.2002 - val_acc: 0.9062\n",
      "Validation accuracy: 0.90625, loss: 0.20019525289535522\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79        27\n",
      "           1       1.00      0.89      0.94       133\n",
      "\n",
      "    accuracy                           0.91       160\n",
      "   macro avg       0.83      0.95      0.87       160\n",
      "weighted avg       0.94      0.91      0.92       160\n",
      "\n",
      "average precision: 0.8602756339691983\n",
      "average recall: 0.9054952618414724\n",
      "average f1: 0.8774775379866562\n",
      "average accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results = []\n",
    "accuracy = []\n",
    "\n",
    "n=5\n",
    "kf = KFold(n_splits=n, random_state=72, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(df_climate_all):\n",
    "    # Garbage Collector: needed to clear GPU memory\n",
    "    gc.collect()\n",
    "    train_documents = df_climate_all.iloc[train_index]\n",
    "    test_documents = df_climate_all.iloc[test_index]\n",
    "\n",
    "    # define train test split in order for NN to be able to train\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_documents['document_vector'], train_documents['climate'], test_size=0.2)\n",
    "\n",
    "\n",
    "    # the numerical representations for each text are now in one column saved as a list\n",
    "    # to be able to feed the data to the Neural Network, a Dataframe is needed with one numerical word representation per column\n",
    "    # rows still represent the document\n",
    "    # zeros are used as padding to get the same number of columns\n",
    "    X_train = pd.DataFrame(X_train.tolist())\n",
    "    X_val = pd.DataFrame(X_val.tolist())\n",
    "    y_train = pd.DataFrame(y_train.tolist())\n",
    "    y_val = pd.DataFrame(y_val.tolist())\n",
    "\n",
    "    # get number of classes\n",
    "    num_classes = train_documents['climate'].nunique()\n",
    "\n",
    "    # vectors themselves, as 2D numpy array\n",
    "    weights = np.array(model_word2vec.vectors)\n",
    "\n",
    "    # to create the embedding matrix that is needed, we need to add an additional row with zeros\n",
    "    # this is necessary as otherwise the model won't be able to handle OOV words\n",
    "    # also the reason for always taking the word index plus one when converting words into numerical features\n",
    "    new_row = np.zeros((1, weights.shape[1]))\n",
    "    # embedding matrix which will be used as the embedding layer in our NN\n",
    "    weights = np.vstack((new_row, weights))\n",
    "\n",
    "    # avoid overfitting\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=3)]\n",
    "\n",
    "    # choose Adam optimizer with a learning rate of 1e-3\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    # batch size depends on the classification task, here 50 was determined as well performing\n",
    "    batch_size = 50\n",
    "\n",
    "    # define input shape for embedding (first) layer of the model\n",
    "    input_shape=X_train.shape[1:]\n",
    "\n",
    "    # model definition\n",
    "    model = Sequential()\n",
    "    # embedding layer, make it trainable to achieve better results\n",
    "    model.add(layers.Embedding(input_dim=weights.shape[0],\n",
    "                               output_dim=weights.shape[1],\n",
    "                               input_length=max_len_for_padding,\n",
    "                               weights=[weights],\n",
    "                               trainable=True))\n",
    "    # dropout is a form of regularization\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    # convolutional 1D layer as we have text, more dimensions needed for e.g. images\n",
    "    # numbers represent no. of filters and kernel size\n",
    "    model.add(layers.Conv1D(256, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.Conv1D(256, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=3))\n",
    "    model.add(layers.Conv1D(512, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.Conv1D(512, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.GlobalAveragePooling1D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    # print summary of model\n",
    "    model.summary()\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"acc\"]\n",
    "    )\n",
    "\n",
    "    # train model and save metrics acc & val_acc\n",
    "    history = model.fit(X_train, y_train, callbacks=callbacks, batch_size=batch_size, epochs=1000, validation_data=(X_val, y_val))\n",
    "\n",
    "    # print last acc & val_acc after training\n",
    "    history = history.history\n",
    "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
    "        acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
    "\n",
    "    # convert testing data to be able to feed it to the model to predict\n",
    "    X_test = pd.DataFrame(test_documents.document_vector.to_list())\n",
    "\n",
    "    # Predict the probabilities for each class\n",
    "    y_probs = model.predict(X_test)\n",
    "    # Get the class with the highest probability for each input data\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "    print(classification_report(test_documents.climate, y_pred))\n",
    "\n",
    "    # append the results to the arrays\n",
    "    results.append(precision_recall_fscore_support(test_documents.climate, y_pred, average='macro'))\n",
    "    accuracy.append(accuracy_score(test_documents.climate, y_pred))\n",
    "\n",
    "# calculate averages\n",
    "avg_precision = np.mean([results[0][0], results[1][0], results[2][0], results[3][0], results[4][0]])\n",
    "avg_recall = np.mean([results[0][1], results[1][1], results[2][1], results[3][1], results[4][1]])\n",
    "avg_f = np.mean([results[0][2], results[1][2], results[2][2], results[3][2], results[4][2]])\n",
    "avg_acc = np.mean(accuracy)\n",
    "\n",
    "print(f\"average precision: {avg_precision}\")\n",
    "print(f\"average recall: {avg_recall}\")\n",
    "print(f\"average f1: {avg_f}\")\n",
    "print(f\"average accuracy: {avg_acc}\")\n",
    "\n",
    "result_climate = {\"macro avg\":{\"average precision\" : avg_precision,\n",
    "                               \"average recall\" : avg_recall,\n",
    "                               \"average f1\" : avg_f,\n",
    "                               \"average accuracy\" : avg_acc\n",
    "                               }}\n",
    "result_climate = pd.DataFrame(result_climate).transpose()\n",
    "with pd.ExcelWriter(\"metrics_new.xlsx\", mode=\"a\", engine=\"openpyxl\", if_sheet_exists='replace') as writer:\n",
    "    result_climate.to_excel(writer, sheet_name=\"glove_climate_NNwEmb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ThreadTheRipper\\FAUbox\\WS22_23\\NLP\\Project/Climate_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ThreadTheRipper\\FAUbox\\WS22_23\\NLP\\Project/Climate_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save(str(Path.cwd()) + '/Climate_model')\n",
    "# load model for further training or prediction\n",
    "# reconstructed_model = tf.keras.models.load_model(\"Climate_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next classification task sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_55 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_220 (Conv1D)         (None, 420, 128)          192128    \n",
      "                                                                 \n",
      " conv1d_221 (Conv1D)         (None, 420, 128)          82048     \n",
      "                                                                 \n",
      " max_pooling1d_55 (MaxPoolin  (None, 140, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_222 (Conv1D)         (None, 140, 256)          164096    \n",
      "                                                                 \n",
      " conv1d_223 (Conv1D)         (None, 140, 256)          327936    \n",
      "                                                                 \n",
      " global_average_pooling1d_55  (None, 256)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,767,279\n",
      "Trainable params: 120,767,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "85/85 [==============================] - 6s 57ms/step - loss: 1.0644 - acc: 0.3886 - val_loss: 0.9352 - val_acc: 0.4434\n",
      "Epoch 2/1000\n",
      "85/85 [==============================] - 5s 53ms/step - loss: 0.8144 - acc: 0.5877 - val_loss: 0.8918 - val_acc: 0.5755\n",
      "Epoch 3/1000\n",
      "85/85 [==============================] - 4s 53ms/step - loss: 0.5970 - acc: 0.7346 - val_loss: 0.8858 - val_acc: 0.6321\n",
      "Epoch 4/1000\n",
      "85/85 [==============================] - 4s 53ms/step - loss: 0.4514 - acc: 0.8128 - val_loss: 0.8627 - val_acc: 0.6981\n",
      "Epoch 5/1000\n",
      "85/85 [==============================] - 5s 53ms/step - loss: 0.3558 - acc: 0.8697 - val_loss: 0.8740 - val_acc: 0.6415\n",
      "Epoch 6/1000\n",
      "85/85 [==============================] - 5s 53ms/step - loss: 0.3234 - acc: 0.9076 - val_loss: 0.9655 - val_acc: 0.7358\n",
      "Epoch 7/1000\n",
      "85/85 [==============================] - 5s 53ms/step - loss: 0.1634 - acc: 0.9431 - val_loss: 1.5222 - val_acc: 0.6604\n",
      "Epoch 8/1000\n",
      "85/85 [==============================] - 4s 53ms/step - loss: 0.1656 - acc: 0.9455 - val_loss: 1.8335 - val_acc: 0.6321\n",
      "Epoch 9/1000\n",
      "85/85 [==============================] - 5s 53ms/step - loss: 0.1479 - acc: 0.9573 - val_loss: 1.8012 - val_acc: 0.6604\n",
      "Validation accuracy: 0.6603773832321167, loss: 1.8012419939041138\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67        40\n",
      "           1       0.63      0.67      0.65        55\n",
      "           2       0.87      0.71      0.78        38\n",
      "\n",
      "    accuracy                           0.69       133\n",
      "   macro avg       0.72      0.69      0.70       133\n",
      "weighted avg       0.70      0.69      0.69       133\n",
      "\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_56 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_224 (Conv1D)         (None, 420, 128)          192128    \n",
      "                                                                 \n",
      " conv1d_225 (Conv1D)         (None, 420, 128)          82048     \n",
      "                                                                 \n",
      " max_pooling1d_56 (MaxPoolin  (None, 140, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_226 (Conv1D)         (None, 140, 256)          164096    \n",
      "                                                                 \n",
      " conv1d_227 (Conv1D)         (None, 140, 256)          327936    \n",
      "                                                                 \n",
      " global_average_pooling1d_56  (None, 256)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,767,279\n",
      "Trainable params: 120,767,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "85/85 [==============================] - 5s 56ms/step - loss: 1.0896 - acc: 0.3783 - val_loss: 1.2079 - val_acc: 0.2830\n",
      "Epoch 2/1000\n",
      "85/85 [==============================] - 4s 53ms/step - loss: 0.7731 - acc: 0.6454 - val_loss: 0.6257 - val_acc: 0.7453\n",
      "Epoch 3/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.5488 - acc: 0.7589 - val_loss: 0.6770 - val_acc: 0.6509\n",
      "Epoch 4/1000\n",
      "85/85 [==============================] - 5s 53ms/step - loss: 0.4040 - acc: 0.8440 - val_loss: 0.5997 - val_acc: 0.8208\n",
      "Epoch 5/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.4123 - acc: 0.8369 - val_loss: 0.6332 - val_acc: 0.8019\n",
      "Epoch 6/1000\n",
      "85/85 [==============================] - 4s 53ms/step - loss: 0.3256 - acc: 0.8889 - val_loss: 0.3809 - val_acc: 0.8396\n",
      "Epoch 7/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.1637 - acc: 0.9456 - val_loss: 0.4853 - val_acc: 0.8208\n",
      "Epoch 8/1000\n",
      "85/85 [==============================] - 5s 53ms/step - loss: 0.1619 - acc: 0.9409 - val_loss: 0.9478 - val_acc: 0.7547\n",
      "Epoch 9/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.2035 - acc: 0.9385 - val_loss: 0.8837 - val_acc: 0.7925\n",
      "Epoch 10/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.2162 - acc: 0.9291 - val_loss: 0.7418 - val_acc: 0.7925\n",
      "Epoch 11/1000\n",
      "85/85 [==============================] - 4s 53ms/step - loss: 0.0813 - acc: 0.9787 - val_loss: 0.6800 - val_acc: 0.8113\n",
      "Validation accuracy: 0.8113207817077637, loss: 0.6799830198287964\n",
      "5/5 [==============================] - 0s 13ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75        32\n",
      "           1       0.67      0.73      0.70        51\n",
      "           2       0.83      0.82      0.82        49\n",
      "\n",
      "    accuracy                           0.76       132\n",
      "   macro avg       0.77      0.75      0.76       132\n",
      "weighted avg       0.76      0.76      0.76       132\n",
      "\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_57 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_228 (Conv1D)         (None, 420, 128)          192128    \n",
      "                                                                 \n",
      " conv1d_229 (Conv1D)         (None, 420, 128)          82048     \n",
      "                                                                 \n",
      " max_pooling1d_57 (MaxPoolin  (None, 140, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_230 (Conv1D)         (None, 140, 256)          164096    \n",
      "                                                                 \n",
      " conv1d_231 (Conv1D)         (None, 140, 256)          327936    \n",
      "                                                                 \n",
      " global_average_pooling1d_57  (None, 256)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,767,279\n",
      "Trainable params: 120,767,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "85/85 [==============================] - 6s 55ms/step - loss: 1.0025 - acc: 0.4894 - val_loss: 0.8193 - val_acc: 0.6132\n",
      "Epoch 2/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.7301 - acc: 0.6028 - val_loss: 1.0509 - val_acc: 0.5094\n",
      "Epoch 3/1000\n",
      "85/85 [==============================] - 4s 53ms/step - loss: 0.6468 - acc: 0.6903 - val_loss: 0.8869 - val_acc: 0.6887\n",
      "Epoch 4/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.5321 - acc: 0.7423 - val_loss: 1.0696 - val_acc: 0.6981\n",
      "Epoch 5/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.4347 - acc: 0.8156 - val_loss: 1.6881 - val_acc: 0.6321\n",
      "Epoch 6/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.2855 - acc: 0.8913 - val_loss: 1.5724 - val_acc: 0.7453\n",
      "Validation accuracy: 0.7452830076217651, loss: 1.5723934173583984\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.46      0.60        35\n",
      "           1       0.66      0.83      0.74        47\n",
      "           2       0.87      0.96      0.91        50\n",
      "\n",
      "    accuracy                           0.78       132\n",
      "   macro avg       0.81      0.75      0.75       132\n",
      "weighted avg       0.80      0.78      0.77       132\n",
      "\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_58 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_232 (Conv1D)         (None, 420, 128)          192128    \n",
      "                                                                 \n",
      " conv1d_233 (Conv1D)         (None, 420, 128)          82048     \n",
      "                                                                 \n",
      " max_pooling1d_58 (MaxPoolin  (None, 140, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_234 (Conv1D)         (None, 140, 256)          164096    \n",
      "                                                                 \n",
      " conv1d_235 (Conv1D)         (None, 140, 256)          327936    \n",
      "                                                                 \n",
      " global_average_pooling1d_58  (None, 256)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,767,279\n",
      "Trainable params: 120,767,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "85/85 [==============================] - 5s 54ms/step - loss: 1.0675 - acc: 0.4350 - val_loss: 0.8879 - val_acc: 0.5377\n",
      "Epoch 2/1000\n",
      "85/85 [==============================] - 4s 51ms/step - loss: 0.8587 - acc: 0.5981 - val_loss: 0.7492 - val_acc: 0.5943\n",
      "Epoch 3/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.6996 - acc: 0.6525 - val_loss: 0.6976 - val_acc: 0.5566\n",
      "Epoch 4/1000\n",
      "85/85 [==============================] - 4s 51ms/step - loss: 0.5869 - acc: 0.6832 - val_loss: 0.6477 - val_acc: 0.6698\n",
      "Epoch 5/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.5248 - acc: 0.7400 - val_loss: 0.6449 - val_acc: 0.7642\n",
      "Epoch 6/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.4533 - acc: 0.8180 - val_loss: 0.8054 - val_acc: 0.6321\n",
      "Epoch 7/1000\n",
      "85/85 [==============================] - 4s 51ms/step - loss: 0.2729 - acc: 0.8936 - val_loss: 0.6302 - val_acc: 0.7358\n",
      "Epoch 8/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.2265 - acc: 0.9196 - val_loss: 0.7522 - val_acc: 0.7170\n",
      "Epoch 9/1000\n",
      "85/85 [==============================] - 4s 51ms/step - loss: 0.2716 - acc: 0.9102 - val_loss: 0.9185 - val_acc: 0.6321\n",
      "Epoch 10/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.1606 - acc: 0.9527 - val_loss: 0.8263 - val_acc: 0.7358\n",
      "Epoch 11/1000\n",
      "85/85 [==============================] - 4s 51ms/step - loss: 0.2515 - acc: 0.9480 - val_loss: 1.0623 - val_acc: 0.7547\n",
      "Epoch 12/1000\n",
      "85/85 [==============================] - 4s 51ms/step - loss: 0.0777 - acc: 0.9693 - val_loss: 0.8456 - val_acc: 0.7264\n",
      "Validation accuracy: 0.7264150977134705, loss: 0.845575213432312\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80        37\n",
      "           1       0.88      0.53      0.66        53\n",
      "           2       0.76      0.98      0.85        42\n",
      "\n",
      "    accuracy                           0.77       132\n",
      "   macro avg       0.78      0.80      0.77       132\n",
      "weighted avg       0.79      0.77      0.76       132\n",
      "\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_59 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_236 (Conv1D)         (None, 420, 128)          192128    \n",
      "                                                                 \n",
      " conv1d_237 (Conv1D)         (None, 420, 128)          82048     \n",
      "                                                                 \n",
      " max_pooling1d_59 (MaxPoolin  (None, 140, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_238 (Conv1D)         (None, 140, 256)          164096    \n",
      "                                                                 \n",
      " conv1d_239 (Conv1D)         (None, 140, 256)          327936    \n",
      "                                                                 \n",
      " global_average_pooling1d_59  (None, 256)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,767,279\n",
      "Trainable params: 120,767,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "85/85 [==============================] - 5s 54ms/step - loss: 1.1046 - acc: 0.3830 - val_loss: 1.0804 - val_acc: 0.3491\n",
      "Epoch 2/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.9142 - acc: 0.5579 - val_loss: 0.8586 - val_acc: 0.6509\n",
      "Epoch 3/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.6022 - acc: 0.7139 - val_loss: 0.6321 - val_acc: 0.7264\n",
      "Epoch 4/1000\n",
      "85/85 [==============================] - 5s 53ms/step - loss: 0.5239 - acc: 0.7707 - val_loss: 0.5923 - val_acc: 0.7830\n",
      "Epoch 5/1000\n",
      "85/85 [==============================] - 4s 51ms/step - loss: 0.3610 - acc: 0.8440 - val_loss: 1.1939 - val_acc: 0.7264\n",
      "Epoch 6/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.2628 - acc: 0.8960 - val_loss: 0.9699 - val_acc: 0.7642\n",
      "Epoch 7/1000\n",
      "85/85 [==============================] - 4s 51ms/step - loss: 0.1708 - acc: 0.9385 - val_loss: 1.7092 - val_acc: 0.7547\n",
      "Epoch 8/1000\n",
      "85/85 [==============================] - 4s 51ms/step - loss: 0.2449 - acc: 0.9196 - val_loss: 1.2280 - val_acc: 0.8019\n",
      "Epoch 9/1000\n",
      "85/85 [==============================] - 4s 52ms/step - loss: 0.0992 - acc: 0.9669 - val_loss: 1.8048 - val_acc: 0.7736\n",
      "Validation accuracy: 0.7735849022865295, loss: 1.8048468828201294\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81        30\n",
      "           1       0.72      0.77      0.74        60\n",
      "           2       0.76      0.74      0.75        42\n",
      "\n",
      "    accuracy                           0.76       132\n",
      "   macro avg       0.78      0.76      0.77       132\n",
      "weighted avg       0.76      0.76      0.76       132\n",
      "\n",
      "average precision: 0.7699597545493784\n",
      "average recall: 0.7505708821797483\n",
      "average f1: 0.749426959226505\n",
      "average accuracy: 0.7519822282980178\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "accuracy = []\n",
    "\n",
    "n=5\n",
    "kf = KFold(n_splits=n, random_state=72, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(df_sentiment_all):\n",
    "    # Garbage Collector: needed to clear GPU memory\n",
    "    gc.collect()\n",
    "    train_documents = df_sentiment_all.iloc[train_index]\n",
    "    test_documents = df_sentiment_all.iloc[test_index]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_documents['document_vector'], train_documents.sentiment, test_size=0.2)\n",
    "    X_train = pd.DataFrame(X_train.tolist())\n",
    "    X_val = pd.DataFrame(X_val.tolist())\n",
    "    y_train = pd.DataFrame(y_train.tolist())\n",
    "    y_val = pd.DataFrame(y_val.tolist())\n",
    "\n",
    "    num_classes = train_documents.sentiment.nunique()\n",
    "\n",
    "    weights = np.array(model_word2vec.vectors)# vectors themselves, as 2D numpy array\n",
    "\n",
    "    # to create the embedding matrix that is needed, we need to add an additional row with zeros\n",
    "    # this is necessary as otherwise the model won't be able to handle OOV words\n",
    "    new_row = np.zeros((1, weights.shape[1]))\n",
    "    # embedding matrix which will be used as the embedding layer in our NN\n",
    "    weights = np.vstack((new_row, weights))\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=5)]\n",
    "\n",
    "    # choose Adam optimizer with a learning rate of 1e-3\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    batch_size = 5\n",
    "\n",
    "    input_shape=X_train.shape[1:]\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=weights.shape[0],\n",
    "                               output_dim=weights.shape[1],\n",
    "                               input_length=max_len_for_padding,\n",
    "                               weights=[weights],\n",
    "                               trainable=True))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Conv1D(128, 5,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.Conv1D(128, 5,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=3))\n",
    "    model.add(layers.Conv1D(256, 5,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.Conv1D(256, 5,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.GlobalAveragePooling1D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=optimizer, metrics=[\"acc\"]\n",
    "    )\n",
    "\n",
    "    # train model and save metrics acc & val_acc\n",
    "    history = model.fit(X_train, y_train, callbacks=callbacks, batch_size=batch_size, epochs=1000, validation_data=(X_val, y_val))\n",
    "\n",
    "    # print last acc & val_acc after training\n",
    "    history = history.history\n",
    "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
    "        acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
    "\n",
    "    X_test = pd.DataFrame(test_documents.document_vector.to_list())\n",
    "    # Predict the probabilities for each class\n",
    "    y_probs = model.predict(X_test)\n",
    "    # Get the class with the highest probability for each input data\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "    print(classification_report(test_documents.sentiment, y_pred))\n",
    "\n",
    "    results.append(precision_recall_fscore_support(test_documents.sentiment, y_pred, average='macro'))\n",
    "    accuracy.append(accuracy_score(test_documents.sentiment, y_pred))\n",
    "\n",
    "avg_precision = np.mean([results[0][0], results[1][0], results[2][0], results[3][0], results[4][0]])\n",
    "avg_recall = np.mean([results[0][1], results[1][1], results[2][1], results[3][1], results[4][1]])\n",
    "avg_f = np.mean([results[0][2], results[1][2], results[2][2], results[3][2], results[4][2]])\n",
    "avg_acc = np.mean(accuracy)\n",
    "\n",
    "print(f\"average precision: {avg_precision}\")\n",
    "print(f\"average recall: {avg_recall}\")\n",
    "print(f\"average f1: {avg_f}\")\n",
    "print(f\"average accuracy: {avg_acc}\")\n",
    "\n",
    "result_sentiment = {\"macro avg\":{\"average precision\" : avg_precision,\n",
    "                               \"average recall\" : avg_recall,\n",
    "                               \"average f1\" : avg_f,\n",
    "                               \"average accuracy\" : avg_acc\n",
    "                               }}\n",
    "result_sentiment = pd.DataFrame(result_sentiment).transpose()\n",
    "with pd.ExcelWriter(\"metrics_new.xlsx\", mode=\"a\", engine=\"openpyxl\", if_sheet_exists='replace') as writer:\n",
    "    result_sentiment.to_excel(writer, sheet_name=\"glove_sentiment_NNwEmb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ThreadTheRipper\\FAUbox\\WS22_23\\NLP\\Project/Sentiment_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ThreadTheRipper\\FAUbox\\WS22_23\\NLP\\Project/Sentiment_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(str(Path.cwd()) + '/Sentiment_model')\n",
    "# reconstructed_model = tf.keras.models.load_model(\"Sentiment_model\")\n",
    "# reconstructed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next classification task - Commitment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_65 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_260 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_261 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_65 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_262 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_263 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_65  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "22/22 [==============================] - 2s 76ms/step - loss: 0.7011 - acc: 0.5308 - val_loss: 0.6711 - val_acc: 0.5755\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.5788 - acc: 0.7536 - val_loss: 0.4075 - val_acc: 0.8396\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.3448 - acc: 0.8649 - val_loss: 0.4192 - val_acc: 0.8491\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.2670 - acc: 0.8863 - val_loss: 0.4011 - val_acc: 0.8585\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.1878 - acc: 0.9123 - val_loss: 0.4271 - val_acc: 0.8679\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.2772 - acc: 0.8768 - val_loss: 0.3859 - val_acc: 0.8585\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.1855 - acc: 0.9218 - val_loss: 0.3948 - val_acc: 0.8679\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.0839 - acc: 0.9787 - val_loss: 0.5005 - val_acc: 0.8679\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.0425 - acc: 0.9882 - val_loss: 0.5788 - val_acc: 0.8679\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.0412 - acc: 0.9858 - val_loss: 0.6232 - val_acc: 0.8868\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.0374 - acc: 0.9858 - val_loss: 0.6801 - val_acc: 0.8774\n",
      "Validation accuracy: 0.8773584961891174, loss: 0.6801098585128784\n",
      "5/5 [==============================] - 0s 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86        74\n",
      "           1       0.82      0.85      0.83        59\n",
      "\n",
      "    accuracy                           0.85       133\n",
      "   macro avg       0.85      0.85      0.85       133\n",
      "weighted avg       0.85      0.85      0.85       133\n",
      "\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_66 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_264 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_265 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_66 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_266 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_267 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_66  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "22/22 [==============================] - 3s 74ms/step - loss: 0.6969 - acc: 0.5485 - val_loss: 0.6624 - val_acc: 0.5755\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.5788 - acc: 0.6950 - val_loss: 0.4434 - val_acc: 0.7925\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.3500 - acc: 0.8723 - val_loss: 0.3598 - val_acc: 0.8491\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.2797 - acc: 0.8983 - val_loss: 0.4563 - val_acc: 0.8208\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.2894 - acc: 0.8723 - val_loss: 0.3941 - val_acc: 0.8396\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.2053 - acc: 0.9173 - val_loss: 0.3688 - val_acc: 0.8679\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.1624 - acc: 0.9480 - val_loss: 0.3657 - val_acc: 0.8585\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.0925 - acc: 0.9716 - val_loss: 0.4126 - val_acc: 0.8491\n",
      "Validation accuracy: 0.849056601524353, loss: 0.41260793805122375\n",
      "5/5 [==============================] - 0s 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87        72\n",
      "           1       0.88      0.77      0.82        60\n",
      "\n",
      "    accuracy                           0.85       132\n",
      "   macro avg       0.85      0.84      0.84       132\n",
      "weighted avg       0.85      0.85      0.85       132\n",
      "\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_67 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_268 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_269 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_67 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_270 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_271 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_67  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "22/22 [==============================] - 2s 70ms/step - loss: 0.6953 - acc: 0.5674 - val_loss: 0.6735 - val_acc: 0.5472\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.6083 - acc: 0.6927 - val_loss: 0.4361 - val_acc: 0.8113\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.3743 - acc: 0.8582 - val_loss: 0.3670 - val_acc: 0.8491\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.3035 - acc: 0.8771 - val_loss: 0.4877 - val_acc: 0.8113\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.2673 - acc: 0.9078 - val_loss: 0.3715 - val_acc: 0.8585\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.1906 - acc: 0.9173 - val_loss: 0.3796 - val_acc: 0.8585\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.1269 - acc: 0.9551 - val_loss: 0.4341 - val_acc: 0.8585\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.1311 - acc: 0.9504 - val_loss: 0.3657 - val_acc: 0.8585\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.0682 - acc: 0.9835 - val_loss: 0.4387 - val_acc: 0.8679\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.1132 - acc: 0.9764 - val_loss: 0.5046 - val_acc: 0.8585\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.0451 - acc: 0.9811 - val_loss: 0.7274 - val_acc: 0.8302\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.0648 - acc: 0.9764 - val_loss: 0.5028 - val_acc: 0.8679\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.0377 - acc: 0.9905 - val_loss: 0.6226 - val_acc: 0.8491\n",
      "Validation accuracy: 0.849056601524353, loss: 0.6226481199264526\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        70\n",
      "           1       0.90      0.92      0.91        62\n",
      "\n",
      "    accuracy                           0.92       132\n",
      "   macro avg       0.92      0.92      0.92       132\n",
      "weighted avg       0.92      0.92      0.92       132\n",
      "\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_68 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_272 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_273 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_68 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_274 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_275 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_68  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "22/22 [==============================] - 2s 70ms/step - loss: 0.6820 - acc: 0.5579 - val_loss: 0.6366 - val_acc: 0.7642\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.5524 - acc: 0.7210 - val_loss: 0.4576 - val_acc: 0.7925\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.3964 - acc: 0.8511 - val_loss: 0.4629 - val_acc: 0.8208\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.2825 - acc: 0.8913 - val_loss: 0.5295 - val_acc: 0.8491\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.3503 - acc: 0.8582 - val_loss: 0.4383 - val_acc: 0.8491\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.1765 - acc: 0.9267 - val_loss: 0.6378 - val_acc: 0.8491\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.0898 - acc: 0.9764 - val_loss: 0.9063 - val_acc: 0.8491\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.0977 - acc: 0.9740 - val_loss: 0.9056 - val_acc: 0.8774\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.0361 - acc: 0.9882 - val_loss: 0.9940 - val_acc: 0.8585\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.0315 - acc: 0.9905 - val_loss: 1.1265 - val_acc: 0.8679\n",
      "Validation accuracy: 0.8679245114326477, loss: 1.1264593601226807\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89        72\n",
      "           1       0.85      0.88      0.87        60\n",
      "\n",
      "    accuracy                           0.88       132\n",
      "   macro avg       0.88      0.88      0.88       132\n",
      "weighted avg       0.88      0.88      0.88       132\n",
      "\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_69 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_276 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_277 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_69 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_278 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_279 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_69  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.6983 - acc: 0.5556 - val_loss: 0.6880 - val_acc: 0.6226\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.5995 - acc: 0.6572 - val_loss: 0.5091 - val_acc: 0.7736\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.4301 - acc: 0.8298 - val_loss: 0.6614 - val_acc: 0.6604\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.3684 - acc: 0.8416 - val_loss: 0.5193 - val_acc: 0.7453\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.2506 - acc: 0.9031 - val_loss: 0.4643 - val_acc: 0.8491\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.1800 - acc: 0.9149 - val_loss: 0.5136 - val_acc: 0.8585\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.1004 - acc: 0.9622 - val_loss: 0.7090 - val_acc: 0.8302\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 1s 61ms/step - loss: 0.1254 - acc: 0.9551 - val_loss: 0.6894 - val_acc: 0.8302\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.0612 - acc: 0.9811 - val_loss: 0.7639 - val_acc: 0.8302\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 0.0214 - acc: 0.9976 - val_loss: 0.9469 - val_acc: 0.8302\n",
      "Validation accuracy: 0.8301886916160583, loss: 0.9469258189201355\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85        82\n",
      "           1       0.73      0.86      0.79        50\n",
      "\n",
      "    accuracy                           0.83       132\n",
      "   macro avg       0.82      0.83      0.82       132\n",
      "weighted avg       0.84      0.83      0.83       132\n",
      "\n",
      "average precision: 0.8624347510449437\n",
      "average recall: 0.8638994246912542\n",
      "average f1: 0.8615840096968383\n",
      "average accuracy: 0.8638642059694691\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "accuracy = []\n",
    "\n",
    "n=5\n",
    "kf = KFold(n_splits=n, random_state=72, shuffle=True)\n",
    "for train_index, test_index in kf.split(df_commitment_all):\n",
    "    # Garbage Collector: needed to clear GPU memory\n",
    "    gc.collect()\n",
    "    train_documents = df_commitment_all.iloc[train_index]\n",
    "    test_documents = df_commitment_all.iloc[test_index]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_documents.document_vector, train_documents.commitment, test_size=0.2)\n",
    "    X_train = pd.DataFrame(X_train.tolist())\n",
    "    X_val = pd.DataFrame(X_val.tolist())\n",
    "    y_train = pd.DataFrame(y_train.tolist())\n",
    "    y_val = pd.DataFrame(y_val.tolist())\n",
    "\n",
    "\n",
    "    num_classes = train_documents.commitment.nunique()\n",
    "\n",
    "    weights = np.array(model_word2vec.vectors)# vectors themselves, as 2D numpy array\n",
    "\n",
    "    # to create the embedding matrix that is needed, we need to add an additional row with zeros\n",
    "    # this is necessary as otherwise the model won't be able to handle OOV words\n",
    "    new_row = np.zeros((1, weights.shape[1]))\n",
    "    # embedding matrix which will be used as the embedding layer in our NN\n",
    "    weights = np.vstack((new_row, weights))\n",
    "\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=5)]\n",
    "\n",
    "    # choose Adam optimizer with a learning rate of 1e-3\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    batch_size = 20\n",
    "\n",
    "    input_shape=X_train.shape[1:]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=weights.shape[0],\n",
    "                               output_dim=weights.shape[1],\n",
    "                               input_length=max_len_for_padding,\n",
    "                               weights=[weights],\n",
    "                               trainable=True))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Conv1D(256, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.Conv1D(256, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=3))\n",
    "    model.add(layers.Conv1D(512, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.Conv1D(512, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.GlobalAveragePooling1D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=optimizer, metrics=[\"acc\"]\n",
    "    )\n",
    "\n",
    "    # train model and save metrics acc & val_acc\n",
    "    history = model.fit(X_train, y_train, callbacks=callbacks, batch_size=batch_size, epochs=1000, validation_data=(X_val, y_val))\n",
    "\n",
    "    # print last acc & val_acc after training\n",
    "    history = history.history\n",
    "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
    "        acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
    "\n",
    "    X_test = pd.DataFrame(test_documents.document_vector.to_list())\n",
    "    # Predict the probabilities for each class\n",
    "    y_probs = model.predict(X_test)\n",
    "    # Get the class with the highest probability for each input data\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "    print(classification_report(test_documents.commitment, y_pred))\n",
    "\n",
    "    results.append(precision_recall_fscore_support(test_documents.commitment, y_pred, average='macro'))\n",
    "    accuracy.append(accuracy_score(test_documents.commitment, y_pred))\n",
    "\n",
    "\n",
    "avg_precision = np.mean([results[0][0], results[1][0], results[2][0], results[3][0], results[4][0]])\n",
    "avg_recall = np.mean([results[0][1], results[1][1], results[2][1], results[3][1], results[4][1]])\n",
    "avg_f = np.mean([results[0][2], results[1][2], results[2][2], results[3][2], results[4][2]])\n",
    "avg_acc = np.mean(accuracy)\n",
    "\n",
    "print(f\"average precision: {avg_precision}\")\n",
    "print(f\"average recall: {avg_recall}\")\n",
    "print(f\"average f1: {avg_f}\")\n",
    "print(f\"average accuracy: {avg_acc}\")\n",
    "\n",
    "result_commitment = {\"macro avg\":{\"average precision\" : avg_precision,\n",
    "                                 \"average recall\" : avg_recall,\n",
    "                                 \"average f1\" : avg_f,\n",
    "                                 \"average accuracy\" : avg_acc\n",
    "                                 }}\n",
    "result_commitment = pd.DataFrame(result_commitment).transpose()\n",
    "with pd.ExcelWriter(\"metrics_new.xlsx\", mode=\"a\", engine=\"openpyxl\", if_sheet_exists='replace') as writer:\n",
    "    result_commitment.to_excel(writer, sheet_name=\"glove_commitment_NNwEmb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ThreadTheRipper\\FAUbox\\WS22_23\\NLP\\Project/Commitment_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ThreadTheRipper\\FAUbox\\WS22_23\\NLP\\Project/Commitment_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(str(Path.cwd()) + '/Commitment_model')\n",
    "# reconstructed_model = tf.keras.models.load_model(\"Commitment_model\")\n",
    "# reconstructed_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next classification task - Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_85 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_340 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_341 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_85 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_342 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_343 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_85  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 4s 59ms/step - loss: 0.6822 - acc: 0.5782 - val_loss: 0.6095 - val_acc: 0.6415\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.5412 - acc: 0.7299 - val_loss: 0.4153 - val_acc: 0.7925\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.4082 - acc: 0.8318 - val_loss: 0.4125 - val_acc: 0.8679\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.3336 - acc: 0.8673 - val_loss: 0.4553 - val_acc: 0.8774\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.2453 - acc: 0.9028 - val_loss: 0.4333 - val_acc: 0.8679\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1405 - acc: 0.9502 - val_loss: 0.5884 - val_acc: 0.8679\n",
      "Validation accuracy: 0.8679245114326477, loss: 0.5883542895317078\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79        72\n",
      "           1       0.74      0.84      0.78        61\n",
      "\n",
      "    accuracy                           0.79       133\n",
      "   macro avg       0.79      0.79      0.79       133\n",
      "weighted avg       0.80      0.79      0.79       133\n",
      "\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_86 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_344 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_345 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_86 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_346 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_347 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_86  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 4s 62ms/step - loss: 0.6821 - acc: 0.5816 - val_loss: 0.6072 - val_acc: 0.6604\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.5159 - acc: 0.7778 - val_loss: 0.4757 - val_acc: 0.7642\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.3580 - acc: 0.8700 - val_loss: 0.4536 - val_acc: 0.7736\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.3067 - acc: 0.8889 - val_loss: 0.4427 - val_acc: 0.7642\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.2460 - acc: 0.9078 - val_loss: 0.5146 - val_acc: 0.7830\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1217 - acc: 0.9504 - val_loss: 0.6337 - val_acc: 0.7642\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1154 - acc: 0.9598 - val_loss: 0.7275 - val_acc: 0.7642\n",
      "Validation accuracy: 0.7641509175300598, loss: 0.7274724245071411\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85        74\n",
      "           1       0.95      0.60      0.74        58\n",
      "\n",
      "    accuracy                           0.81       132\n",
      "   macro avg       0.85      0.79      0.79       132\n",
      "weighted avg       0.84      0.81      0.80       132\n",
      "\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_87 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_348 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_349 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_87 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_350 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_351 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_87  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 4s 60ms/step - loss: 0.6894 - acc: 0.5674 - val_loss: 0.6605 - val_acc: 0.5660\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.5644 - acc: 0.6879 - val_loss: 0.7748 - val_acc: 0.7264\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.4050 - acc: 0.8534 - val_loss: 0.4668 - val_acc: 0.7925\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.3407 - acc: 0.8936 - val_loss: 0.4702 - val_acc: 0.7830\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.2497 - acc: 0.9102 - val_loss: 0.4410 - val_acc: 0.8019\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1657 - acc: 0.9385 - val_loss: 0.4950 - val_acc: 0.8019\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1438 - acc: 0.9645 - val_loss: 0.5801 - val_acc: 0.8113\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.0609 - acc: 0.9764 - val_loss: 0.7779 - val_acc: 0.8113\n",
      "Validation accuracy: 0.8113207817077637, loss: 0.7778597474098206\n",
      "5/5 [==============================] - 0s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88        82\n",
      "           1       0.91      0.64      0.75        50\n",
      "\n",
      "    accuracy                           0.84       132\n",
      "   macro avg       0.86      0.80      0.82       132\n",
      "weighted avg       0.85      0.84      0.83       132\n",
      "\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_88 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_352 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_353 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_88 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_354 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_355 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_88  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 4s 58ms/step - loss: 0.6949 - acc: 0.5768 - val_loss: 0.5930 - val_acc: 0.7925\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.4963 - acc: 0.7825 - val_loss: 0.4112 - val_acc: 0.8585\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.4117 - acc: 0.8345 - val_loss: 0.3943 - val_acc: 0.8679\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.3031 - acc: 0.8794 - val_loss: 0.3692 - val_acc: 0.8302\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.2140 - acc: 0.9291 - val_loss: 0.4375 - val_acc: 0.8302\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1596 - acc: 0.9362 - val_loss: 0.6106 - val_acc: 0.8585\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1134 - acc: 0.9574 - val_loss: 0.5558 - val_acc: 0.8396\n",
      "Validation accuracy: 0.8396226167678833, loss: 0.5558486580848694\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88        78\n",
      "           1       0.87      0.74      0.80        54\n",
      "\n",
      "    accuracy                           0.85       132\n",
      "   macro avg       0.85      0.83      0.84       132\n",
      "weighted avg       0.85      0.85      0.85       132\n",
      "\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_89 (Embedding)    (None, 420, 300)          120000300 \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 420, 300)          0         \n",
      "                                                                 \n",
      " conv1d_356 (Conv1D)         (None, 420, 256)          230656    \n",
      "                                                                 \n",
      " conv1d_357 (Conv1D)         (None, 420, 256)          196864    \n",
      "                                                                 \n",
      " max_pooling1d_89 (MaxPoolin  (None, 140, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_358 (Conv1D)         (None, 140, 512)          393728    \n",
      "                                                                 \n",
      " conv1d_359 (Conv1D)         (None, 140, 512)          786944    \n",
      "                                                                 \n",
      " global_average_pooling1d_89  (None, 512)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,609,518\n",
      "Trainable params: 121,609,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 4s 58ms/step - loss: 0.6940 - acc: 0.5650 - val_loss: 0.6896 - val_acc: 0.5472\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.6179 - acc: 0.6927 - val_loss: 0.4567 - val_acc: 0.7925\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 0.4746 - acc: 0.8156 - val_loss: 0.6007 - val_acc: 0.6509\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.3880 - acc: 0.8487 - val_loss: 0.3871 - val_acc: 0.8302\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.2770 - acc: 0.8936 - val_loss: 0.3463 - val_acc: 0.8302\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1964 - acc: 0.9196 - val_loss: 0.3956 - val_acc: 0.7925\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1142 - acc: 0.9622 - val_loss: 0.5156 - val_acc: 0.7925\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 3s 54ms/step - loss: 0.1055 - acc: 0.9669 - val_loss: 0.6052 - val_acc: 0.7830\n",
      "Validation accuracy: 0.7830188870429993, loss: 0.6052117347717285\n",
      "5/5 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.69      0.80        85\n",
      "           1       0.63      0.94      0.75        47\n",
      "\n",
      "    accuracy                           0.78       132\n",
      "   macro avg       0.79      0.82      0.78       132\n",
      "weighted avg       0.84      0.78      0.78       132\n",
      "\n",
      "average precision: 0.8302398673061215\n",
      "average recall: 0.806000698039432\n",
      "average f1: 0.8036175504630855\n",
      "average accuracy: 0.8139553429027113\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "accuracy = []\n",
    "\n",
    "n=5\n",
    "kf = KFold(n_splits=n, random_state=72, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(df_specificity_all):\n",
    "    # Garbage Collector: needed to clear GPU memory\n",
    "    gc.collect()\n",
    "    train_documents = df_specificity_all.iloc[train_index]\n",
    "    test_documents = df_specificity_all.iloc[test_index]\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_documents.document_vector, train_documents.specificity, test_size=0.2)\n",
    "    X_train = pd.DataFrame(X_train.tolist())\n",
    "    X_val = pd.DataFrame(X_val.tolist())\n",
    "    y_train = pd.DataFrame(y_train.tolist())\n",
    "    y_val = pd.DataFrame(y_val.tolist())\n",
    "\n",
    "    num_classes = train_documents.specificity.nunique()\n",
    "\n",
    "    weights = np.array(model_word2vec.vectors)# vectors themselves, as 2D numpy array\n",
    "\n",
    "    # to create the embedding matrix that is needed, we need to add an additional row with zeros\n",
    "    # this is necessary as otherwise the model won't be able to handle OOV words\n",
    "    new_row = np.zeros((1, weights.shape[1]))\n",
    "    # embedding matrix which will be used as the embedding layer in our NN\n",
    "    weights = np.vstack((new_row, weights))\n",
    "\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=3)]\n",
    "\n",
    "    # choose Adam optimizer with a learning rate of 1e-3\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    batch_size = 8\n",
    "\n",
    "    input_shape=X_train.shape[1:]\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=weights.shape[0],\n",
    "                               output_dim=weights.shape[1],\n",
    "                               input_length=max_len_for_padding,\n",
    "                               weights=[weights],\n",
    "                               trainable=True))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Conv1D(256, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.Conv1D(256, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=3))\n",
    "    model.add(layers.Conv1D(512, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.Conv1D(512, 3,\n",
    "                            activation='relu',\n",
    "                            bias_initializer='random_uniform',\n",
    "                            padding='same'))\n",
    "    model.add(layers.GlobalAveragePooling1D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=optimizer, metrics=[\"acc\"]\n",
    "    )\n",
    "\n",
    "    # train model and save metrics acc & val_acc\n",
    "    history = model.fit(X_train, y_train, callbacks=callbacks, batch_size=batch_size, epochs=1000, validation_data=(X_val, y_val))\n",
    "\n",
    "    # print last acc & val_acc after training\n",
    "    history = history.history\n",
    "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
    "        acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
    "\n",
    "    X_test = pd.DataFrame(test_documents.document_vector.to_list())\n",
    "    # Predict the probabilities for each class\n",
    "    y_probs = model.predict(X_test)\n",
    "    # Get the class with the highest probability for each input data\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "    print(classification_report(test_documents.specificity, y_pred))\n",
    "\n",
    "    results.append(precision_recall_fscore_support(test_documents.specificity, y_pred, average='macro'))\n",
    "    accuracy.append(accuracy_score(test_documents.specificity, y_pred))\n",
    "\n",
    "avg_precision = np.mean([results[0][0], results[1][0], results[2][0], results[3][0], results[4][0]])\n",
    "avg_recall = np.mean([results[0][1], results[1][1], results[2][1], results[3][1], results[4][1]])\n",
    "avg_f = np.mean([results[0][2], results[1][2], results[2][2], results[3][2], results[4][2]])\n",
    "avg_acc = np.mean(accuracy)\n",
    "\n",
    "print(f\"average precision: {avg_precision}\")\n",
    "print(f\"average recall: {avg_recall}\")\n",
    "print(f\"average f1: {avg_f}\")\n",
    "print(f\"average accuracy: {avg_acc}\")\n",
    "\n",
    "result_specificity = {\"macro avg\":{\"average precision\" : avg_precision,\n",
    "                                  \"average recall\" : avg_recall,\n",
    "                                  \"average f1\" : avg_f,\n",
    "                                  \"average accuracy\" : avg_acc\n",
    "                                  }}\n",
    "result_specificity = pd.DataFrame(result_specificity).transpose()\n",
    "with pd.ExcelWriter(\"metrics_new.xlsx\", mode=\"a\", engine=\"openpyxl\", if_sheet_exists='replace') as writer:\n",
    "    result_specificity.to_excel(writer, sheet_name=\"glove_specificity_NNwEmb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ThreadTheRipper\\FAUbox\\WS22_23\\NLP\\Project/Specificity_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ThreadTheRipper\\FAUbox\\WS22_23\\NLP\\Project/Specificity_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(str(Path.cwd()) + '/Specificity_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
